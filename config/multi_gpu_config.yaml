# Qwen3-VL 多卡微调配置文件
# ==================================

# 微调方法配置
finetune_method: "full"  # 微调方法: "lora" 或 "full" (全量微调)

# 模型配置
model_name: "/root/.cache/modelscope/hub/models/qwen/Qwen3-VL-2B-Instruct"  # 基础模型路径
model_dtype: "bfloat16"  # 模型精度 (bfloat16 通常更适合大模型)

# 数据配置
dataset_path: "./vlm_finetune_dataset.json"  # 训练数据集路径
validation_split: 0.1  # 验证集比例

# LoRA 配置 (仅在 finetune_method = "lora" 时生效)
lora_r: 64  # LoRA秩 (控制适配器矩阵大小)
lora_alpha: 16  # LoRA缩放因子
lora_dropout: 0.05  # LoRA层的dropout概率
target_modules:  # 需要应用LoRA的模块列表
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"
  - "gate_proj"
  - "up_proj"
  - "down_proj"
  - "embed_tokens"
  - "lm_head"

# 训练超参数
num_train_epochs: 3  # 训练轮数
per_device_train_batch_size: 2  # 每个设备的训练批次大小 (多卡可以使用更大值)
per_device_eval_batch_size: 2   # 每个设备的评估批次大小
gradient_accumulation_steps: 4  # 梯度累积步数 (调节以保持与单卡相似的有效批次大小)
learning_rate: 2.0e-04          # 学习率
weight_decay: 0.05              # 权重衰减系数
warmup_ratio: 0.1               # 预热比例 (学习率预热)

# 日志和保存配置
logging_steps: 10               # 日志记录间隔步数
save_steps: 500                 # 模型保存间隔步数
eval_steps: 20                  # 验证评估间隔步数
save_total_limit: 3             # 最大保存检查点数量
output_dir: "./qwen3-vl-2b-instruct-lora-multigpu"  # 输出目录
overwrite_output_dir: true      # 是否覆盖输出目录

# 训练优化设置
gradient_checkpointing: true    # 是否启用梯度检查点节省显存
fp16: false                     # 是否使用fp16混合精度训练
bf16: true                      # 是否使用bfloat16混合精度训练
max_grad_norm: 1.0              # 梯度裁剪最大范数
logging_dir: "./logs"           # 日志目录

# 分布式训练配置
ddp_find_unused_parameters: false  # DDP是否查找未使用的参数
dataloader_drop_last: true         # 是否丢弃最后一个不完整的批次
local_rank: 0                      # 本地Rank (由torch.distributed自动设置)

# 数据加载器设置
dataloader_pin_memory: true        # 是否固定内存 (多卡环境下通常设为true)
dataloader_num_workers: 4          # 数据加载器工作进程数 (可适当增加以利用多核CPU)
max_steps: -1                      # 最大训练步数 (-1表示无限制，使用epochs)