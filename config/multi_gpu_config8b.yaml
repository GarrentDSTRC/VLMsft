
# Qwen3-VL 多卡微调配置文件
# ==================================

# 微调方法配置
finetune_method: "lora"  # 微调方法: "lora" 或 "full" (全量微调)

# 模型配置
model_name: "/wangzhangyuan-oss/Qwen3-VL-8B-Instruct"  # 基础模型路径
model_dtype: "bfloat16"  # 模型精度 (bfloat16 通常更适合大模型)

# 数据配置
dataset_path: "./data/action_data.json" # 训练数据集路径
validation_split: 0.1  # 验证集比例

# LoRA 配置 (仅在 finetune_method = "lora" 时生效)
lora_r: 64  # LoRA秩 (控制适配器矩阵大小)
lora_alpha: 16  # LoRA缩放因子
lora_dropout: 0.05  # LoRA层的dropout概率
target_modules:  # 需要应用LoRA的模块列表
  # 语言模型模块
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"
  - "gate_proj"
  - "up_proj"
  - "down_proj"
  - "embed_tokens"
  - "lm_head"
  # # 视觉模型模块 (VIT相关) - 从实际模型结构中提取的精确模块路径
  # - "visual.patch_embed.proj"  # 视觉补丁嵌入投影层
  # - "visual.pos_embed"  # 位置嵌入
  # - "visual.blocks.*.attn.qkv"  # 所有注意力层的QKV投影
  # - "visual.blocks.*.attn.proj"  # 所有注意力层的输出投影
  # - "visual.blocks.*.mlp.linear_fc1"  # 所有MLP前馈层的第一层
  # - "visual.blocks.*.mlp.linear_fc2"  # 所有MLP前馈层的第二层
  # - "visual.blocks.*.norm1"  # 所有层归一化层1
  # - "visual.blocks.*.norm2"  # 所有层归一化层2
  # - "visual.merger.*"  # 视觉合并模块
  # - "visual.deepstack_merger_list.*"  # 深堆栈合并模块
# 训练超参数
num_train_epochs: 50  # 训练轮数
per_device_train_batch_size: 6 # 每个设备的训练批次大小 (多卡可以使用更大值)
per_device_eval_batch_size: 8  # 每个设备的评估批次大小
gradient_accumulation_steps: 4  # 梯度累积步数 (调节以保持与单卡相似的有效批次大小)
learning_rate: 2.0e-04          # 学习率
weight_decay: 0.2             # 权重衰减系数
warmup_ratio: 0.1               # 预热比例 (学习率预热)

# 日志和保存配置
logging_steps: 10               # 日志记录间隔步数
save_steps: 60                 # 模型保存间隔步数
eval_steps: 20                  # 验证评估间隔步数
save_total_limit: 5             # 最大保存检查点数量
output_dir: "./qwen3-vl-2b-instruct-lora"  # 输出目录
overwrite_output_dir: true      # 是否覆盖输出目录

# 训练优化设置
gradient_checkpointing: true    # 是否启用梯度检查点节省显存
fp16: true                    # 是否使用fp16混合精度训练
bf16: false                     # 是否使用bfloat16混合精度训练
max_grad_norm: 1.0              # 梯度裁剪最大范数
logging_dir: "./logs"           # 日志目录

# 分布式训练配置
ddp_find_unused_parameters: false  # DDP是否查找未使用的参数
dataloader_drop_last: false        # 是否丢弃最后一个不完整的批次
local_rank: 0                      # 本地Rank (由torch.distributed自动设置)

# 数据加载器设置
dataloader_pin_memory: true        # 是否固定内存 (多卡环境下通常设为true)
dataloader_num_workers: 8          # 数据加载器工作进程数 (可适当增加以利用多核CPU)
max_steps: -1                      # 最大训练步数 (-1表示无限制，使用epochs)